{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Training TensorFlow (Keras) Deep Learning Models Efficiently\n",
    "\n",
    "In this notebook, we present an **efficient methodology** to train Deep Learning models for image classification.\n",
    "\n",
    "In practical Deep Learning projects, data is typically stored on disks. The **tf.Data** API provides faster solutions to load large data from the disk and apply various transformations on it. This API uses the **Dataset** object for representing a very large set of elements. It allows us to assert finer control over the data pipeline.\n",
    "\n",
    "Using the tf.Data API, we construct a Dataset object from the local image repository. Then, the Dataset object is transformed for loading image-label pairs. Prior loading, we convert each encoded image (i.e., PNG-encoded images) as a Tensor object, type-casting it (e.g., float32), scaling, getting the image label from the stored images (from the image sub-directories organized by class names). Finally, image-label pairs are shuffled and put into batches for training the model. \n",
    "\n",
    "This program uses the **distributed training** technique. It utilizes multiple GPUs on a single node. The specification for the number and type of GPUs should be provided in the SLURM .sh job request file. More information on distributed training: https://keras.io/guides/distributed_training/\n",
    "\n",
    "\n",
    "\n",
    "## Distributed Training: Single-host & Multi-device Synchronous Training\n",
    "\n",
    "We use the **tf.distribute** API to train a TensorFlow Keras model on multiple GPUs installed on a single machine (node). \n",
    "\n",
    "Specifically, we use the tf.distribute.Strategy with tf.keras. The tf.distribute.Strategy is integrated into tf.keras, which is a high-level API to build and train models. By integrating into tf.keras backend, it is seamless for use to distribute the training written in the Keras training framework.\n",
    "\n",
    "More information on the distributed training with Keras:\n",
    "https://www.tensorflow.org/tutorials/distribute/keras\n",
    "\n",
    "\n",
    "### Parallelism Technique:\n",
    "Via the tf.distribute API, we implement the synchronous **data parallelism** technique. In this technique, a single model gets replicated on multiple devices or multiple machines. Each of them processes different batches of data, then they merge their results. The different replicas of the model stay in sync after each batch they process. Synchronicity keeps the model convergence behavior identical to what you would see for single-device training.\n",
    "\n",
    "\n",
    "### How to use the tf.distribute API for distributed training:\n",
    "To perform single-host, multi-device synchronous training with a TensorFlow Keras model, we use the tf.distribute.MirroredStrategy API. \n",
    "\n",
    "Following are the 3 simple steps.\n",
    "\n",
    "- Instantiate a MirroredStrategy.\n",
    "By default, the strategy will use all GPUs available on a single machine.\n",
    "\n",
    "- Use the strategy object to open a scope, and within this scope, \n",
    "create all the Keras objects you need that contain variables. \n",
    "More specifically, within the distribution scope:\n",
    "- Create the model\n",
    "- Compile the model (by defining the optimizer and metrics)\n",
    "\n",
    "- Train the model via the fit() method as usual (outside the scope).\n",
    "\n",
    "**Note**: we need to use tf.data.Dataset objects to load data in a multi-device or distributed workflow.\n",
    "\n",
    "\n",
    "\n",
    "## Local Data Repository\n",
    "\n",
    "This program assumes that the training and test data (i.e., images) are stored locally, and organized in nested directories as follows:\n",
    "- train\n",
    "   - class_name_1\n",
    "   - class_name_2\n",
    "   ...\n",
    "- test\n",
    "   - class_name_1\n",
    "   - class_name_2\n",
    "   ...\n",
    "\n",
    "Specifically, there should be two root directories named \"train\" and \"test\". The sub-directories should be named after the classes.\n",
    "\n",
    "## Data Augmentation\n",
    "\n",
    "In the distributed training setting, we recommend performing data augmentation inside the model so that it is done by GPUs. We use Keras image preproessing layer API to build the data augmentation pipeline. https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing\n",
    "\n",
    "The augmentation layer can be used inside the data preprocessing pipeline when training is done by a single device (CPU or GPU).\n",
    "\n",
    "Thus, while the data preprocessing pipeline is built using tf.Data API, the data augmentation pipeline is based on Keras image preproessing layer API, which can be integrated in the preprocessing pipeline when need be.\n",
    "\n",
    "For a detail discussion on various augmentation approaches, see the following GitHub repository:\n",
    "https://github.com/rhasanbd/Data-Augmentation-for-Deep-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use comet ml to track the progress of the training and get training statistics\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Create an experiment with the api key:\n",
    "experiment = Experiment(\n",
    "    api_key=\"\",\n",
    "    project_name=\"\",\n",
    "    workspace=\"\",\n",
    "    log_code = True,\n",
    "    auto_param_logging=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import statements\n",
    "import warnings\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "\n",
    "import torch # torch is used to get GPU information\n",
    "import tensorflow as tf\n",
    "\n",
    "# Python Imaging Library is used for opening image files\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import pathlib # required to access the image folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU\n"
     ]
    }
   ],
   "source": [
    "# Variable to store number of available GPUs\n",
    "num_of_gpu = 0\n",
    "\n",
    "# Determine the number of GPUs available\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell torch to use the GPU    \n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    # Get the number of GPUs\n",
    "    num_of_gpu = torch.cuda.device_count()\n",
    "    print(\"Number of available GPU(s) %d.\" % num_of_gpu)\n",
    "\n",
    "    print(\"GPU Name: \", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU available, using the CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "\n",
      "Number of GPU(s): 1\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create a MirroredStrategy\n",
    "The training model must be created and compiled inside the scope of this strategy\n",
    "'''\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"\\nNumber of GPU(s): {}\".format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Data Pipeline \n",
    "\n",
    "\n",
    "We create a data pipeline to perform the following tasks:\n",
    "- Load the data from the local storage into the program's memory\n",
    "- Prepare the dataset for training\n",
    "\n",
    "\n",
    "## Load Data from Storage \n",
    "\n",
    "We use TensorFlow's Data API tf.data to load and preprocess a large dataset efficiently. This API loads the data as tf Dataset object, which is required for distributed training (using multiple GPUs) and faster processing.\n",
    "\n",
    "\n",
    "## Approach for Loading the Images and their Labels\n",
    "\n",
    "- Create the list of file names (filepaths)\n",
    "- Create tf Dataset that consumes the list of file names \n",
    "- From this list, load the (image, label) pairs\n",
    "\n",
    "\n",
    "## Create the List of File Names (Filepaths)\n",
    "\n",
    "We get the list of file names (filepaths) by accessig the image folders. We use Path and glob methods in the pathlib module for accessing the image folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train directory path:  /Users/hasan/datasets/cifar10/train\n",
      "Test directory path:  /Users/hasan/datasets/cifar10/test\n",
      "\n",
      "Number of training files:  50000\n",
      "Number of test files:  10000\n",
      "\n",
      "Path of the first training image:  /Users/hasan/datasets/cifar10/train/cat/3975.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x1A6F4B8630>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the path to the root directory\n",
    "ROOT_DIR = os.path.abspath(os.curdir)\n",
    "\n",
    "# Create the path to the image directories\n",
    "train_dir = os.path.join(ROOT_DIR, 'datasets/cifar10/train')\n",
    "test_dir = os.path.join(ROOT_DIR, 'datasets/cifar10/test')\n",
    "\n",
    "print(\"Train directory path: \", train_dir)\n",
    "print(\"Test directory path: \", test_dir)\n",
    "\n",
    "# Create a list of training filenames\n",
    "train_data_dir = pathlib.Path(train_dir)\n",
    "train_file_paths = list(train_data_dir.glob('*/*')) # Get the list of all training image filepaths\n",
    "print(\"\\nNumber of training files: \", len(train_file_paths))\n",
    "\n",
    "# Create a list of test filenames\n",
    "test_data_dir = pathlib.Path(test_dir)\n",
    "test_file_paths = list(test_data_dir.glob('*/*')) # Get the list of all test image filepaths\n",
    "print(\"Number of test files: \", len(test_file_paths))\n",
    "\n",
    "print(\"\\nPath of the first training image: \", train_file_paths[0])\n",
    "PIL.Image.open(train_file_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a tf Dataset that Consumes the List of File Names (Filepaths)\n",
    "\n",
    "There are two options to create the image file list Dataset.\n",
    "\n",
    "- Option 1: Create the file list Dataset by using the Dataset.from_tensor_slices() method\n",
    "- Option 2: Create the file list Dataset by using the Dataset.list_files() method\n",
    "\n",
    "Note that, before using Option 2, if the filenames have already been globbed, then re-globbing every filename with the list_files() method may result in poor performance with remote storage systems.\n",
    "\n",
    "Since, we have already globbed the file names & paths in the first step, we do not use Option 2.\n",
    "However, the code for option 2 is provided (commented out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train filenames list length:  50000\n",
      "Test filenames list length:  10000\n",
      "\n",
      "Number of samples (image files) in training dataset:  50000\n",
      "Number of samples (image files) in test dataset:  10000\n"
     ]
    }
   ],
   "source": [
    "#_______________________Option 1: \"from_tensor_slices\" method____________________________\n",
    "\n",
    "\n",
    "'''\n",
    "Get filenames (filepaths) as strings in a list (for training & testing images) \n",
    "'''\n",
    "train_fnames=[]\n",
    "for fname in train_file_paths:\n",
    "    train_fnames.append(str(fname))\n",
    "\n",
    "print(\"Train filenames list length: \", len(train_fnames))\n",
    "\n",
    "test_fnames=[]\n",
    "for fname in test_file_paths:\n",
    "    test_fnames.append(str(fname))\n",
    "\n",
    "print(\"Test filenames list length: \", len(test_fnames))\n",
    "\n",
    "\n",
    "'''\n",
    "Shuffle the filepaths\n",
    "'''\n",
    "random.shuffle(train_fnames)\n",
    "random.shuffle(test_fnames)\n",
    "\n",
    "\n",
    "'''\n",
    "Create the filepath list Dataset (for training & testing images) \n",
    "'''\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_fnames)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_fnames)\n",
    "\n",
    "\n",
    "\n",
    "#_______________________Option 2: \"list_flies\" method (NOT USED)__________________________\n",
    "\n",
    "# #Get a training dataset of all files (list of all image paths) matching the glob pattern\n",
    "# train_dataset = tf.data.Dataset.list_files(str(train_data_dir/'*/*'))\n",
    "# \n",
    "# #Get a test dataset of all files (list of all image paths) matching the glob pattern\n",
    "# test_dataset = tf.data.Dataset.list_files(str(test_data_dir/'*/*'))\n",
    "\n",
    "\n",
    "train_dataset_size = train_dataset.cardinality().numpy()\n",
    "test_dataset_size = test_dataset.cardinality().numpy()\n",
    "\n",
    "\n",
    "print(\"\\nNumber of samples (image files) in training dataset: \", train_dataset_size)\n",
    "print(\"Number of samples (image files) in test dataset: \", test_dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Some Filepaths from the Dataset\n",
    "\n",
    "We display the file names (filepaths) of five files from the Dataset. Observe that\n",
    "- The file names are shuffled\n",
    "- The letter \"b\" appears before the filepaths because TensorFlow parses the strings as byte-strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'/Users/hasan/datasets/cifar10/train/ship/2878.png'\n",
      "b'/Users/hasan/datasets/cifar10/train/dog/3067.png'\n",
      "b'/Users/hasan/datasets/cifar10/train/bird/0458.png'\n",
      "b'/Users/hasan/datasets/cifar10/train/cat/1455.png'\n",
      "b'/Users/hasan/datasets/cifar10/train/cat/1348.png'\n"
     ]
    }
   ],
   "source": [
    "for f in train_dataset.take(5):\n",
    "    print(f.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Loading the (image, label) Pair from the Filepath\n",
    "\n",
    "\n",
    "We define the \"load_labeled_data\" function that takes a filepath and returns the image-label pair. The image is loaded as a float32 Tensor (scaled) and the label is loaded as one-hot encoded int32 Tensor. This function is used by the Dataset to load image-label pairs from the list of filepaths.\n",
    "\n",
    "The \"load_labeled_data\" function is defined based on a few other functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class names:\n",
      " ['cat', 'dog', 'truck', 'bird', 'airplane', 'ship', 'frog', 'horse', 'deer', 'automobile']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Get class names as a list\n",
    "The class names will be used by the \"get_label\" function\n",
    "NOTE: it only works if the data is structured in nested sub-directories named after the classes.\n",
    "'''\n",
    "CLASS_NAMES = os.listdir(train_data_dir)\n",
    "print(\"\\nClass names:\\n\", CLASS_NAMES)\n",
    "\n",
    "\n",
    "'''\n",
    "Function to get the label of an image (file) from its path and class names\n",
    "The labels are one-hot encoded\n",
    "'''\n",
    "def get_label(file_path):\n",
    "  # Convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory (i.e., name of the class)\n",
    "  return tf.cast(parts[-2] == CLASS_NAMES, dtype=tf.int32)\n",
    "  \n",
    "\n",
    "'''\n",
    "This function reads a PNG-encoded image into a uint8 tensor\n",
    "- Converts the uint8 tensor into float32\n",
    "- Scales the tensor into the range [0,1] automatically while converting to float32\n",
    "  Thus, we don't need to scale the images separately\n",
    "- Resizes the image\n",
    "Note: if the image encoding is other than PNG, then a suitable decode method should be used.\n",
    "'''   \n",
    "def process_image(image, image_height=32, image_width=32):  \n",
    "    # Decode a PNG-encoded image to a uint8 tensor\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "\n",
    "    # Convert the unit8 tensor to floats in the [0,1] range\n",
    "    # Images that are represented using floating point values are expected to have values in the range [0,1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    \n",
    "    # Resize image\n",
    "    image = tf.image.resize(image, [image_height, image_width])\n",
    "    \n",
    "    return image\n",
    "    \n",
    "'''\n",
    "This functions returns a one-hot encoded labeled float32 tensor of an image \n",
    "based on its file path\n",
    "'''\n",
    "def load_labeled_data(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = process_image(img)\n",
    "    label = get_label(file_path)\n",
    "    return img, label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Prepare the Dataset for Training\n",
    "\n",
    "To prepare the Dataset for training, we need to:\n",
    "- Get the (image, label) pairs from the list Dataset object (that contains list of file paths)\n",
    "- Load these pairs in memory\n",
    "- Create mini-batches for training and validation\n",
    "\n",
    "The Dataset object provides convenient methods for these and additional useful data preprocessing tasks. We chain the relevant methods on the Dataset object to:\n",
    "- Load (image, label) pairs into the Dataset object\n",
    "- Cache Dataset\n",
    "- Shuffle Dataset\n",
    "- Create mini-batches\n",
    "- Perform data augmentation\n",
    "- Prefetch a mini-batch\n",
    "\n",
    "First, we call the Dataset's map() method that applies the data loading function \"load_labeled_data\" on each sample of the dataset. The returned new object will emit transformed images and their one-hot encoded labels in the original order.\n",
    "\n",
    "Second, we cache the data locally. The \"cache\" method stores dataset elements in memory (by default) or in file for future reusing.\n",
    "- The first time the dataset is iterated over (i.e., first epoch), its elements will be cached either in the specified file or in memory. \n",
    "- Subsequent iterations (i.e., epochs) will use the cached data. This will save some operations (e.g., file opening, data reading, parsing, transforming, etc.) from being executed during each epoch.\n",
    "\n",
    "Caching should be used judiciously.\n",
    "- Smaller dataset (that fits into memory): use the cache method. \n",
    "- Large dataset:  typically is sharded (split in multiple files), and do not fit in memory. Thus, it should not be cached in memory.\n",
    "\n",
    "The cache method will produce exactly the same elements during each iteration (epoch) through the dataset. \n",
    "For randomizing the iteration order, we need to call the shuffle method after calling cache.\n",
    "\n",
    "Third, we randomly shuffle the dataset using the shuffle method. The shuffle method randomly shuffles the elements of the dataset. First, it fills a buffer with the dataset with buffer_size elements. Then, it randomly samples elements from this buffer, replacing the selected elements with new elements. For perfect shuffling, the buffer_size should be greater than or equal to the size of the dataset.  However, for large datasets, this isn't possible. So, we will use a large enough buffer_size.\n",
    "\n",
    "Fourth, we batch the dataset. In the batch method, we set \"drop_remainder\" to True so that the size of the training set is divisible by the batch_size. It is done by removing enough training examples. \n",
    "\n",
    "Finally, we prefetch a batch to decouple the time when data is produced from the time when data is consumed. The transformation uses a background thread and an internal buffer to prefetch elements from the input dataset ahead of the time they are requested. The number of elements to prefetch should be equal to (or possibly greater than)  the number of batches consumed by a single training step. Instead of manually tuning this value, we set it to tf.data.AUTOTUNE, which will prompt the tf.data runtime to tune the value dynamically at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(ds, mini_batch, epochs, shuffle=False, buffer_size=0, augment=False, augment_func=None):\n",
    "\n",
    "    '''\n",
    "    The map method applies the argument function (i.e., load_labeled_data) \n",
    "    to each element of the dataset, \n",
    "    and returns a new dataset containing the transformed elements (i.e., image-label pairs), \n",
    "    in the same order as they appeared in the input.\n",
    "    '''\n",
    "    ds = ds.map(load_labeled_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    '''\n",
    "    Cache the dataset elements in memory\n",
    "    '''\n",
    "    ds = ds.cache()\n",
    "  \n",
    "    '''\n",
    "    Shuffle the dataset\n",
    "    '''\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size)\n",
    "      \n",
    "    '''\n",
    "    Repeat the shuffled dataset\n",
    "    '''  \n",
    "    ds = ds.repeat(count=epochs)\n",
    "    \n",
    "\n",
    "    '''\n",
    "    Batch all datasets\n",
    "    '''\n",
    "    ds = ds.batch(mini_batch, drop_remainder=True)\n",
    "\n",
    "    '''\n",
    "    Use data augmentation only on the training set\n",
    "    When training is done using GPUs in a distributed setting, \n",
    "    for efficiency, perform data augmentation inside the model. \n",
    "    '''\n",
    "    if augment:\n",
    "        ds = ds.map(lambda x, y: (augment_func(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    '''\n",
    "    Repeats the batch so each original value is seen \"count\" times\n",
    "    Increasing \"count\" will increase the number of steps per epoch\n",
    "    '''\n",
    "    #ds = ds.repeat(count=2) \n",
    "    \n",
    "    '''\n",
    "    Use buffered prefecting on all datasets\n",
    "    '''\n",
    "    return ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size of training mini-batch:  64\n",
      "Size of test mini-batch:  64\n",
      "\n",
      "Buffer Size:  50000\n",
      "\n",
      "Epochs:  5\n",
      "Data available to run for 5 epochs\n",
      "Unlimited data available:  False\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Determine the size of mini-batch for training\n",
    "It should be a multiple of BATCH_SIZE_PER_REPLICA \n",
    "The multiplication factor is determined by the number of available GPUs (or strategy.num_replicas_in_sync)\n",
    "'''\n",
    "                                    \n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "\n",
    "if(num_of_gpu > 0):\n",
    "    size_of_mini_batch = BATCH_SIZE_PER_REPLICA*num_of_gpu\n",
    "else:\n",
    "    size_of_mini_batch = BATCH_SIZE_PER_REPLICA # Uses the CPU, as no GPU is available\n",
    "\n",
    "\n",
    "'''\n",
    "Size of test mini-batch \n",
    "'''\n",
    "size_of_mini_batch_test = size_of_mini_batch\n",
    "\n",
    "print(\"\\nSize of training mini-batch: \", size_of_mini_batch)\n",
    "print(\"Size of test mini-batch: \", size_of_mini_batch_test)\n",
    "\n",
    "\n",
    "'''\n",
    "Used by the \"shuffle\" method. \n",
    "For small dataset, it should be equal or larger than training set.\n",
    "'''\n",
    "buffer_size =   train_dataset_size\n",
    "print(\"\\nBuffer Size: \", buffer_size)\n",
    "\n",
    "\n",
    "'''\n",
    "Set the number of training epochs.\n",
    "This is required by the repeat method.\n",
    "'''\n",
    "no_of_epochs = 5\n",
    "print(\"\\nEpochs: \", no_of_epochs)\n",
    "\n",
    "\n",
    "'''\n",
    "Perform data preprocessing by the CPU.\n",
    "It is efficient as it ensures that the GPUs will be used only for model training.\n",
    "'''\n",
    "with tf.device('/cpu:0'):\n",
    "    train_loader = prepare_dataset(train_dataset, size_of_mini_batch, no_of_epochs, \n",
    "                                   shuffle=True, buffer_size=buffer_size, augment=False, augment_func=None)\n",
    "    test_loader = prepare_dataset(test_dataset, size_of_mini_batch_test, no_of_epochs)\n",
    "    no_of_steps_per_epoch = train_dataset_size//size_of_mini_batch\n",
    "    total_no_of_steps = train_loader.cardinality().numpy()\n",
    "    print(\"Data available to run for %d epochs\" % (total_no_of_steps//no_of_steps_per_epoch))\n",
    "    print(\"Unlimited data available: \", (train_loader.cardinality() == tf.data.INFINITE_CARDINALITY).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Display some training images from a training Dataset batch\n",
    "'''\n",
    "image_batch, label_batch = next(iter(train_loader))\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image_batch[i])\n",
    "    label = label_batch[i]\n",
    "    plt.title(CLASS_NAMES[tf.argmax(label)])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation Layer\n",
    "\n",
    "We define a Data Augmentation layer by using Keras Image Preprocessing Layer API.\n",
    "\n",
    "When training is done by a single device (CPU or GPU), data augmentation should be done during preprocessing. However, in distributed training (using multiple GPUs), we can expedite the training time by integrating data augmentation into the learning model so that it is done by GPUs.\n",
    "\n",
    "In this demo, we perform data augmentation inside the model. For this, we ceate a data augmentation layer by defining a function named \"data_augmentation_layer\". The function is based on a data augmentation Sequential layer object of class \"DataAugmentation\". This custom layer object is included in the learning model.\n",
    "\n",
    "If we need the custom layer to be serializable as part of a learning model, we should implement a get_config() method.\n",
    "\n",
    "To learn more about data augmentation, see:\n",
    "https://github.com/rhasanbd/Data-Augmentation-for-Deep-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define the DataAugmentation class using the tf.Keras' Sequential API.\n",
    "It creates a data augmentation layer for performing following augmentation to input data:\n",
    "- Resize (increase the size)\n",
    "- Random zoom\n",
    "- Random rotation\n",
    "- Random horizontal flip\n",
    "- Random crop (restore the original size)\n",
    "'''\n",
    "\n",
    "class DataAugmentation(tf.keras.layers.Layer):\n",
    "    def __init__(self, original_size, increased_size, rotation_angle_degree, zoom_height_factor, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.augmentation_layers = [] \n",
    "        self.augmentation_layers.append(tf.keras.layers.experimental.preprocessing.Resizing(increased_size, increased_size))\n",
    "        self.augmentation_layers.append(tf.keras.layers.experimental.preprocessing.RandomZoom(zoom_height_factor, width_factor=None, \n",
    "                                                                                              fill_mode='nearest', interpolation='bilinear'))\n",
    "        self.augmentation_layers.append(tf.keras.layers.experimental.preprocessing.RandomRotation(rotation_angle_degree/360, \n",
    "                                                                                                  fill_mode='nearest', interpolation='bilinear'))\n",
    "        self.augmentation_layers.append(tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"))\n",
    "        self.augmentation_layers.append(tf.keras.layers.experimental.preprocessing.RandomCrop(original_size, original_size))\n",
    "        \n",
    "      \n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.augmentation_layers:\n",
    "            Z = layer(Z)\n",
    "        return Z\n",
    "    \n",
    "    # Required for the custom object's serialization\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\"augmentation\": self.augmentation_layers})\n",
    "        return config\n",
    "  \n",
    "\n",
    "'''\n",
    "This function creates a sequential tf.Keras layer for performing data augmentation\n",
    "'''\n",
    "def data_augmentation_layer(original_size, increased_size, rotation_angle_degree, zoom_height_factor):\n",
    "    \n",
    "    d_augmentation = tf.keras.models.Sequential(name='Data-Augmentation')\n",
    "    d_augmentation.add(DataAugmentation(original_size, increased_size, rotation_angle_degree, zoom_height_factor))\n",
    "\n",
    "    return d_augmentation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Creating the Training Model\n",
    "\n",
    "We define a function to create the VGG model. First, we define a custom VGG_Block class, which is used to create a VGGNet by the \"create_vgg_net\" function. The function also uses the custom data augmentation layer.\n",
    "\n",
    "For more information on the VGGNet, see:\n",
    "https://github.com/rhasanbd/Convolutional-Neural-Networks/blob/main/CNN-9-Notable%20Architectures-I.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Block Class\n",
    "\n",
    "For serializability of this custom class, we override its get_config() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define the VGG block class using Keras Sequential API \n",
    "The VGG_Block class takes two arguments:\n",
    "- conv_block_number: number of convolutional layers \n",
    "- num_of_channels: number of output channels \n",
    "'''\n",
    "class VGG_Block(tf.keras.layers.Layer):\n",
    "    def __init__(self, conv_block_number, num_of_channels, weight_decay, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_layers = [] \n",
    "        for _ in range(conv_block_number):\n",
    "            self.conv_layers.append(tf.keras.layers.Conv2D(filters=num_of_channels, kernel_size=(3, 3), strides=1,\n",
    "                                padding='same', kernel_regularizer=tf.keras.regularizers.l2(weight_decay), use_bias=False))\n",
    "            self.conv_layers.append(tf.keras.layers.BatchNormalization())\n",
    "            self.conv_layers.append(tf.keras.layers.Activation(\"relu\"))\n",
    "        \n",
    "        self.pool_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.conv_layers:\n",
    "            Z = layer(Z)\n",
    "            \n",
    "        Z = self.pool_layer(Z)\n",
    "        return Z\n",
    "        \n",
    "    # Required for the custom object's serialization\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            \"conv_layers\": self.conv_layers,\n",
    "            \"pool_layer\": self.pool_layer,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Creating a VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vgg_net(conv_blocks, width, height, channels, num_classes, weight_decay, augmentation=False, **kwargs):\n",
    "    \n",
    "    vgg_net = tf.keras.models.Sequential(name='VGG')\n",
    "    \n",
    "    vgg_net.add(tf.keras.layers.InputLayer(input_shape=(width, height, channels)))\n",
    "    \n",
    "    # Data augmentation layer\n",
    "    if(augmentation):\n",
    "        vgg_net.add(data_augmentation_layer(**kwargs))\n",
    "    \n",
    "    # Convolutional layers based on the VGG_Block object\n",
    "    for (conv_block_number, num_of_channels) in conv_blocks:\n",
    "            vgg_net.add(VGG_Block(conv_block_number, num_of_channels, weight_decay))\n",
    "    \n",
    "    # Flatten the convnet output to feed it with fully-connected layers\n",
    "    vgg_net.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    # Fully-connected layers\n",
    "    vgg_net.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "    vgg_net.add(tf.keras.layers.Dropout(0.5))\n",
    "    vgg_net.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
    "    \n",
    "    return vgg_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg__block (VGG_Block)       (None, 16, 16, 32)        10336     \n",
      "_________________________________________________________________\n",
      "vgg__block_1 (VGG_Block)     (None, 8, 8, 64)          55808     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                262208    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 329,002\n",
      "Trainable params: 328,618\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Delete the TensorFlow graph before creating a new model, otherwise memory overflow will occur.\n",
    "'''\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "'''\n",
    "To reproduce the same result by the model in each iteration, we use fixed seeds for random number generation. \n",
    "'''\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "'''\n",
    "Define the optimizer\n",
    "'''\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-1, momentum=0.9, nesterov=False)\n",
    "\n",
    "\n",
    "'''\n",
    "We use the layer_info variable for creating the VGG model.\n",
    "It contains a list of tuples (one per block).\n",
    "Each tuple contains two values: \n",
    "- number of convolutional layers\n",
    "- the number of output channels\n",
    "These two arguments are used to call the VGG_Block function\n",
    "'''\n",
    "layer_info = ((2, 32), (2, 64)) \n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Open a strategy scope to create and compile the model\n",
    "Everything that creates variables should be under the strategy scope\n",
    "'''\n",
    "with strategy.scope():\n",
    "    \n",
    "    '''\n",
    "    If the \"augment\" is set to True, then pass the following keyword arguments.\n",
    "    - original_size\n",
    "    - increased_size\n",
    "    - rotation_angle_degree\n",
    "    - zoom_height_factor\n",
    "    '''\n",
    "    model = create_vgg_net(layer_info, 32, 32, channels=3, num_classes=10,\n",
    "                           weight_decay=0.001,\n",
    "                           augment=True, \n",
    "                           original_size=32, \n",
    "                           increased_size=36, \n",
    "                           rotation_angle_degree=20, \n",
    "                           zoom_height_factor=0.6)\n",
    "    model.summary()\n",
    "    loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(loss=loss_object,\n",
    "              optimizer=optimizer,\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training started ...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hasan/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4870: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  '\"`categorical_crossentropy` received `from_logits=True`, but '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 112s 139ms/step - loss: 2.5084 - categorical_accuracy: 0.0987 - val_loss: 2.3282 - val_categorical_accuracy: 0.1001\n",
      "Epoch 2/5\n",
      "781/781 [==============================] - 104s 133ms/step - loss: 2.3135 - categorical_accuracy: 0.0971 - val_loss: 2.3058 - val_categorical_accuracy: 0.1002\n",
      "Epoch 3/5\n",
      "781/781 [==============================] - 108s 138ms/step - loss: 2.3070 - categorical_accuracy: 0.0989 - val_loss: 2.3091 - val_categorical_accuracy: 0.1001\n",
      "Epoch 4/5\n",
      "781/781 [==============================] - 109s 139ms/step - loss: 2.2983 - categorical_accuracy: 0.1040 - val_loss: 2.1984 - val_categorical_accuracy: 0.1527\n",
      "Epoch 5/5\n",
      "781/781 [==============================] - 113s 145ms/step - loss: 2.1340 - categorical_accuracy: 0.1803 - val_loss: 2.0962 - val_categorical_accuracy: 0.2165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/hasan/Saved_Models/CIFAR10_VGG/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/hasan/Saved_Models/CIFAR10_VGG/assets\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The model name variable is used for model serialization\n",
    "'''\n",
    "model_name = \"CIFAR10_VGG\"\n",
    "\n",
    "'''\n",
    "Create model checkpoint \"callback\" object to save only the best performing models\n",
    "'''\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(model_name, save_best_only=True)\n",
    "\n",
    "\n",
    "'''\n",
    "Create a TensorBoard \"callback\" object for the learning schedule\n",
    "'''\n",
    "lschedule_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.1,\n",
    "                              patience=10, min_lr=0.000001, mode='auto', verbose=1)\n",
    "\n",
    "\n",
    "'''\n",
    "Train the model\n",
    "'''\n",
    "print(\"\\nTraining started ...\")\n",
    "\n",
    "history = model.fit(train_loader, \n",
    "                    epochs=no_of_epochs,\n",
    "                    steps_per_epoch=train_dataset_size // size_of_mini_batch,\n",
    "                    validation_steps=test_dataset_size // size_of_mini_batch_test,\n",
    "                    verbose=1,\n",
    "                    validation_data=test_loader,\n",
    "                    callbacks=[lschedule_cb])\n",
    "\n",
    "\n",
    "'''\n",
    "Save the model\n",
    "\n",
    "Save the entire model to disk in the TensorFlow SavedModel format by using the model.save() method. \n",
    "It is the default format with model.save().\n",
    "Another option is the older Keras H5 format (not used here). \n",
    "\n",
    "SavedModel is a comprehensive save format that saves: \n",
    "- the model architecture \n",
    "- weights\n",
    "- the traced Tensorflow subgraphs of the call functions \n",
    "\n",
    "This enables Keras to restore both built-in layers as well as custom objects (e.g., data augmentation layer).\n",
    "\n",
    "\n",
    "Calling model.save(model_name) creates a folder named model_name. \n",
    "It contains the following directories and file (.pb):\n",
    "- assets  \n",
    "- saved_model.pb  \n",
    "- variables\n",
    "\n",
    "The saved_model.pb file stores the actual TensorFlow program, or model. \n",
    "It includes the model architecture, and training configuration (e.g., optimizer, losses, and metrics) \n",
    "\n",
    "The variables directory contains weights (i.e., a standard training checkpoint).\n",
    "\n",
    "The assets directory contains files used by the TensorFlow graph.\n",
    "For example text files used to initialize vocabulary tables.\n",
    "\n",
    "For more informattion, see:\n",
    "https://keras.io/guides/serialization_and_saving/\n",
    "'''\n",
    "\n",
    "# Path to the Saved_Models diretory in which the model will be serialized\n",
    "saved_model_directory = os.path.join(ROOT_DIR, 'Saved_Models')\n",
    "saved_model_path = os.path.join(saved_model_directory, model_name)\n",
    "\n",
    "model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "We evaluate the trained model using various techniques.\n",
    "\n",
    "- Evaluate the Model using the History Object\n",
    "- Evaluate the Model using its predict() Method on the Batched Test Dataset Object\n",
    "- Evaluate the Model using its predict() Method on the Full Test Set\n",
    "- Evaluation using the Saved Model\n",
    "\n",
    "\n",
    "\n",
    "## Evaluate the Model using the History Object\n",
    "\n",
    "The model's fit method returns a History object, which we use for getting information on the model's performance. \n",
    "\n",
    "The History object has an attribute named \"history\" that contains a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:  5\n",
      "\n",
      "CIFAR10_VGG Train Accuracy: 0.180\n",
      "CIFAR10_VGG Train Loss: 2.134\n",
      "\n",
      "CIFAR10_VGG Validation Accuracy: 0.217\n",
      "CIFAR10_VGG Validation Loss: 2.096\n"
     ]
    }
   ],
   "source": [
    "numOfEpochs = len(history.history['loss'])\n",
    "print(\"Epochs: \", numOfEpochs)\n",
    "\n",
    "train_acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "# Read the last value from the list that represents final epoch statistics\n",
    "print(\"\\n{} Train Accuracy: {:.3f}\".format(model_name, train_acc[-1]))\n",
    "print(\"{} Train Loss: {:.3f}\".format(model_name, train_loss[-1]))\n",
    "\n",
    "print(\"\\n{} Validation Accuracy: {:.3f}\".format(model_name, val_acc[-1]))\n",
    "print(\"{} Validation Loss: {:.3f}\".format(model_name, val_loss[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model using its predict() Method on the Batched Test Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.217\n",
      "Test Loss: 2.096\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_loader.take(-1), verbose=0)\n",
    "print(\"\\nTest Accuracy: {:.3f}\".format(test_accuracy))\n",
    "print(\"Test Loss: {:.3f}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model using its predict() Method on the Full Test Set\n",
    "\n",
    "For evaluating the model using the test set, we need to create: \n",
    "- an array of test images (as Tensors)\n",
    "- an array of integer labels \n",
    "\n",
    "Then, we predict integer lables using the test images and compute model's performance using the true integer labels. Following evaluation metrics are used:\n",
    "- Accuracy\n",
    "- Confusion matrix\n",
    "- Classification report\n",
    "\n",
    "\n",
    "\n",
    "## Create Arrays of Test Images and Labels\n",
    "\n",
    "From the test Dataset object we create an array of tensor images and an array of their labels. The loaded labels are one-hot encoded, which we convert as an array of integer labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Test Images:  10000\n",
      "\n",
      "Test Images Array Shape:  (10000, 32, 32, 3)\n",
      "Test Images Array Data Type:  <dtype: 'float32'>\n",
      "\n",
      "Test Labels Array Shape (one-hot encoded):  (10000, 10)\n",
      "Test Labels Array Data Type (one-hot encoded):  <dtype: 'int32'>\n",
      "\n",
      "Length of the integer labels list:  10000\n",
      "\n",
      "Shape of the integer label array:  (10000,)\n",
      "Data type of the integer label array:  <dtype: 'int64'>\n",
      "\n",
      "Sample one-hot encoded label:  tf.Tensor([0 0 0 0 0 0 1 0 0 0], shape=(10,), dtype=int32)\n",
      "Sample integer label:  tf.Tensor(6, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset as image-label (one-hot encoded) pairs\n",
    "ds_test = test_dataset.map(load_labeled_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Create lists of test images and their labels (one-hot encoded) \n",
    "images_test_list = []\n",
    "labels_test_list = []\n",
    "count = 0\n",
    "for images, labels in ds_test.take(-1):\n",
    "    count += 1\n",
    "    images_test_list.append(images)\n",
    "    labels_test_list.append(labels)\n",
    "\n",
    "print(\"Number of Test Images: \", count)\n",
    "\n",
    "\n",
    "# Convert the lists of images and labels (one-hot encoded) as arrays\n",
    "#images_test = np.asarray(images_test_list)\n",
    "#labels_test_one_hot_encoded = np.asarray(labels_test_list)\n",
    "images_test = tf.convert_to_tensor(images_test_list)\n",
    "labels_test_one_hot_encoded = tf.convert_to_tensor(labels_test_list)\n",
    "\n",
    "print(\"\\nTest Images Array Shape: \", images_test.shape)\n",
    "print(\"Test Images Array Data Type: \", images_test.dtype)\n",
    "\n",
    "\n",
    "print(\"\\nTest Labels Array Shape (one-hot encoded): \", labels_test_one_hot_encoded.shape)\n",
    "print(\"Test Labels Array Data Type (one-hot encoded): \", labels_test_one_hot_encoded.dtype)\n",
    "\n",
    "# Create a list of integer labels by converting one-hot encoded labels \n",
    "labels_test_list = []\n",
    "for i in range(labels_test_one_hot_encoded.shape[0]):\n",
    "    labels_test_list.append(tf.argmax(labels_test_one_hot_encoded[i]))\n",
    "\n",
    "# Number of integer labels \n",
    "print(\"\\nLength of the integer labels list: \", len(labels_test_list))\n",
    "\n",
    "# Convert the integer labels list as a numpy array\n",
    "#labels_test = np.asarray(labels_test_list)\n",
    "labels_test = tf.convert_to_tensor(labels_test_list)\n",
    "print(\"\\nShape of the integer label array: \", labels_test.shape)\n",
    "print(\"Data type of the integer label array: \", labels_test.dtype)\n",
    "\n",
    "print(\"\\nSample one-hot encoded label: \", labels_test_one_hot_encoded[670])\n",
    "print(\"Sample integer label: \", labels_test[670])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions using the Test Images Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the one-hot encoded predictions array:  (10000, 10)\n",
      "Data type of the one-hot encoded predictions array:  float32\n",
      "\n",
      "Shape of the integer predictions array:  (10000,)\n",
      "Data type of the integer predictions array:  <dtype: 'int64'>\n",
      "\n",
      "Sample one-hot encoded predicted label:  [0.16312894 0.14544518 0.06731509 0.1218327  0.0626487  0.03945874\n",
      " 0.13469273 0.10271773 0.10691939 0.05584068]\n",
      "Sample integer true label:  tf.Tensor(0, shape=(), dtype=int64)\n",
      "\n",
      "Test Accuracy:  0.2166\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[881   0  37   2   3   0   0  77   0   0]\n",
      " [846   0  13   4   4   0   0 133   0   0]\n",
      " [356   0 630   0   9   0   0   5   0   0]\n",
      " [781   0  35  10  47   0   0 127   0   0]\n",
      " [463   0 200  37 273   0   0  27   0   0]\n",
      " [381   0 407  31 180   0   0   1   0   0]\n",
      " [871   0  24   2   1   0   0 102   0   0]\n",
      " [582   0  27   9   9   0   0 372   1   0]\n",
      " [724   0  20   4  21   0   0 231   0   0]\n",
      " [310   0 677   0   8   0   0   5   0   0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.88      0.24      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.30      0.63      0.41      1000\n",
      "           3       0.10      0.01      0.02      1000\n",
      "           4       0.49      0.27      0.35      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.34      0.37      0.36      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.22     10000\n",
      "   macro avg       0.14      0.22      0.14     10000\n",
      "weighted avg       0.14      0.22      0.14     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hasan/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predict one-hot encoded labels for the test images\n",
    "labels_test_predicted_one_hot_encoded = model.predict(images_test)\n",
    "print(\"\\nShape of the one-hot encoded predictions array: \", labels_test_predicted_one_hot_encoded.shape)\n",
    "print(\"Data type of the one-hot encoded predictions array: \", labels_test_predicted_one_hot_encoded.dtype)\n",
    "\n",
    "# Create an array of integer labels by converting one-hot encoded labels array \n",
    "# This is done by getting the label/index of the highest probability class\n",
    "labels_test_predicted = tf.argmax(labels_test_predicted_one_hot_encoded, axis=1) \n",
    "print(\"\\nShape of the integer predictions array: \", labels_test_predicted.shape)\n",
    "print(\"Data type of the integer predictions array: \", labels_test_predicted.dtype)\n",
    "\n",
    "print(\"\\nSample one-hot encoded predicted label: \", labels_test_predicted_one_hot_encoded[670])\n",
    "print(\"Sample integer true label: \", labels_test_predicted[670])\n",
    "\n",
    "test_accuracy = np.mean(labels_test_predicted == labels_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy)\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_test, labels_test_predicted))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(labels_test, labels_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation using the Saved Model\n",
    "\n",
    "We evaluate the saved model using its predict() method on the full test dataset.\n",
    "\n",
    "The saved model can be loaded by using tf.keras.models.load_model() method. If the model contains custom layers, then we need to set the \"custom_objects\" argument. It should be a dictionary mapping names (strings) to custom classes or functions to be considered during deserialization.\n",
    "\n",
    "In this demo, the training model is a custom object. Because it is created using the \"vgg\" function that is based on the custom data augmentation layer and the VGG_Block custom layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the one-hot encoded predictions array:  (10000, 10)\n",
      "Data type of the one-hot encoded predictions array:  float32\n",
      "\n",
      "Shape of the integer predictions array:  (10000,)\n",
      "Data type of the integer predictions array:  <dtype: 'int64'>\n",
      "\n",
      "Sample one-hot encoded predicted label:  [0.16312894 0.14544518 0.06731509 0.1218327  0.0626487  0.03945874\n",
      " 0.13469273 0.10271773 0.10691939 0.05584068]\n",
      "Sample integer true label:  tf.Tensor(0, shape=(), dtype=int64)\n",
      "\n",
      "Test Accuracy:  0.2166\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[881   0  37   2   3   0   0  77   0   0]\n",
      " [846   0  13   4   4   0   0 133   0   0]\n",
      " [356   0 630   0   9   0   0   5   0   0]\n",
      " [781   0  35  10  47   0   0 127   0   0]\n",
      " [463   0 200  37 273   0   0  27   0   0]\n",
      " [381   0 407  31 180   0   0   1   0   0]\n",
      " [871   0  24   2   1   0   0 102   0   0]\n",
      " [582   0  27   9   9   0   0 372   1   0]\n",
      " [724   0  20   4  21   0   0 231   0   0]\n",
      " [310   0 677   0   8   0   0   5   0   0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.88      0.24      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.30      0.63      0.41      1000\n",
      "           3       0.10      0.01      0.02      1000\n",
      "           4       0.49      0.27      0.35      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.34      0.37      0.36      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.22     10000\n",
      "   macro avg       0.14      0.22      0.14     10000\n",
      "weighted avg       0.14      0.22      0.14     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model (containing custom objec) using with the custom_object argument\n",
    "saved_model = tf.keras.models.load_model(saved_model_path, custom_objects={\"create_vgg_net\": create_vgg_net})\n",
    "\n",
    "\n",
    "# Predict one-hot encoded labels for the test images\n",
    "labels_test_predicted_one_hot_encoded = saved_model.predict(images_test)\n",
    "print(\"\\nShape of the one-hot encoded predictions array: \", labels_test_predicted_one_hot_encoded.shape)\n",
    "print(\"Data type of the one-hot encoded predictions array: \", labels_test_predicted_one_hot_encoded.dtype)\n",
    "\n",
    "# Create an array of integer labels by converting one-hot encoded labels array \n",
    "# This is done by getting the label/index of the highest probability class\n",
    "labels_test_predicted = tf.argmax(labels_test_predicted_one_hot_encoded, axis=1) \n",
    "print(\"\\nShape of the integer predictions array: \", labels_test_predicted.shape)\n",
    "print(\"Data type of the integer predictions array: \", labels_test_predicted.dtype)\n",
    "\n",
    "print(\"\\nSample one-hot encoded predicted label: \", labels_test_predicted_one_hot_encoded[670])\n",
    "print(\"Sample integer true label: \", labels_test_predicted[670])\n",
    "\n",
    "test_accuracy = np.mean(labels_test_predicted == labels_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy)\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_test, labels_test_predicted))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(labels_test, labels_test_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
